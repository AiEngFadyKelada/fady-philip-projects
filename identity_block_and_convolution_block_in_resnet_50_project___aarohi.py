# -*- coding: utf-8 -*-
"""Identity Block and Convolution Block in ResNet 50 project | Aarohi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/196vTW8CuYEo6aCeU-Qr-La63JoVIfJVD
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add # Import Add layer here
from keras.models import Model,load_model
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
import pydot
from IPython.display import SVG
from keras.utils import plot_model
from keras.initializers import glorot_uniform
import scipy.misc
from matplotlib.pyplot import imshow
# %matplotlib inline

import keras.backend as K
K.set_image_data_format('channels_last')
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
!pip install --force-reinstall tensorflow
!python3 -m venv myenv
!source myenv/bin/activate
!pip install --force-reinstall tensorflow

import tensorflow as tf

import warnings


!pip install kaggle
import json
from zipfile import ZipFile
kaggle_credentails = json.load(open("kaggle.json"))
os.environ['KAGGLE_USERNAME'] = kaggle_credentails["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentails["key"]
!kaggle datasets download -d robinreni/house-rooms-image-dataset
!ls
# Unzip the downloaded dataset
with ZipFile("house-rooms-image-dataset.zip", 'r') as zip_ref:
    zip_ref.extractall()

"""#**Identity Block**"""

#Identity Block
def identity_block(X, f, filters):
    F1,F2,F3=filters  #F1=64,F2=64,F3=256
    X_shortcut=X

    # First Layer
    X=Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding='valid')(X)
    X=BatchNormalization(axis=3)(X)
    X=Activation('relu')(X)

    #Second Layer                   #f=3
    X=Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same')(X)
    X=BatchNormalization(axis=3)(X)
    X=Activation('relu')(X)

    #Third Layer
    X=Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid')(X)
    X=BatchNormalization(axis=3)(X)

    #Final Step: add shortcut value to F(X) and pass it through a RELU Activation
    X=Add()([X,X_shortcut]) # Add F(X)+X before applying RELU Activation
    X=Activation('relu')(X)

    return X

"""#**Convolutional Block**"""

#Convolutional Block
def Convolutional_Block(X,f,filters,s=2):
  #retrieve filters
  F1,F2,F3=filters

  #save the input value
  X_shortcut=X

  #First Layer
  X=Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding='valid')(X)
  X=BatchNormalization()(X)
  X=Activation('relu')(X)

  #Second Layer  (f,f)=3*3 filter by default
  X=Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same')(X)
  X=BatchNormalization()(X)
  X=Activation('relu')(X)

  #Third Layer
  X=Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid')(X)
  X=BatchNormalization()(X)

  #Shortcut path
  X_shortcut=Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding='valid')(X_shortcut)
  X_shortcut=BatchNormalization()(X_shortcut)

  #Final Step : Add shortcut value here, and path it through a RELU Acticvation
  X=Add()([X,X_shortcut])
  X=Activation('relu')(X)

  return X

dataset_path=os.listdir("House_Room_Dataset")
print(dataset_path)
room_types=os.listdir("House_Room_Dataset")
remove=['Kitchen', 'Bathroom']
room_types=[i for i in room_types if i not in remove]
print(room_types)

print(room_types)

rooms=[]
im_paths=[]
labels=[]
for room_type in room_types:
    all_rooms=os.listdir(os.path.join("House_Room_Dataset"+"/"+room_type))
    print(all_rooms)
    for room in all_rooms:
         labels.append(room_type)
         rooms.append((room_type,str("House_Room_Dataset")+"/"+room_type+"/"+room))
         im_paths.append(str("House_Room_Dataset")+"/"+room_type+"/"+room)
print(labels[:])
print(rooms[:])
print(im_paths[:])

df=pd.DataFrame(data=rooms,columns=['room_type','image_path'])
df

room_count=df['room_type'].value_counts()
print('Total number of rooms in dataset:',len(df['room_type']))
print('Rooms in each category:\n',room_count)

images=[]
im_size=224
for i in im_paths:
    img=cv2.imread(i)
    img=cv2.resize(img,(im_size,im_size))
    images.append(img)
images

images=np.array(images)
images=images.astype('float32')/255.0
print(images)
print(labels)

print(images.shape)

from sklearn.preprocessing import LabelEncoder,OneHotEncoder
y=labels
y_LE=LabelEncoder()
y=y_LE.fit_transform(y)
print(y)
y=y.reshape(-1,1)
OHE=OneHotEncoder()
Y=OHE.fit_transform(y)
print(Y,'\n',Y.shape)

# Add the tf.config options
tf.config.set_soft_device_placement(True)
tf.config.experimental.set_visible_devices([], 'GPU')

"""#**ResNet 50 Model Architecture**"""

channels=3
input_shape=(im_size,im_size,channels)
classes=3
def ResNet50(input_shape=(im_size,im_size,channels),classes=classes):

#implementation of ResNet50 Architecture :
# Conv2D,BatchNormalization,ReLu,MaxPooling,ConvBlock, IDBlock*2,,ConvBlock, IDBlock*3,,ConvBlock, IDBlock*5,,ConvBlock, IDBlock*2

  X_input=Input(input_shape)
  # zero padding= 224+3+3= 230 which means image_input_shape=230*230
  X=ZeroPadding2D((3,3))(X_input) # the size of the image wouldn't decrease faster than what we want ( we are increasing the size of the image)

  #stage 1:
  X=Conv2D(64,(7,7),strides=(2,2))(X)
  X=BatchNormalization(axis=3)(X)
  X=Activation('relu')(X)
  X=MaxPooling2D((3,3),strides=(2,2))(X)

  #stage 2:
  X=Convolutional_Block(X,f=3,filters=[64,64,256],s=1)
  X=identity_block(X,3,[64,64,256])
  X=identity_block(X,3,[64,64,256])

  #stage 3:
  X=Convolutional_Block(X,f=3,filters=[128,128,512],s=2)
  X=identity_block(X,3,[128,128,512])
  X=identity_block(X,3,[128,128,512])
  X=identity_block(X,3,[128,128,512])

  #stage 4:
  X=Convolutional_Block(X,f=3,filters=[256,256,1024],s=2)
  X=identity_block(X,3,[256,256,1024])
  X=identity_block(X,3,[256,256,1024])
  X=identity_block(X,3,[256,256,1024])
  X=identity_block(X,3,[256,256,1024])
  X=identity_block(X,3,[256,256,1024])

  #stage 5:
  X=Convolutional_Block(X,f=3,filters=[512,512,2048],s=2)
  X=identity_block(X,3,[512,512,2048])
  X=identity_block(X,3,[512,512,2048])

  #AVG Pool
  X=AveragePooling2D((2,2),name='avg_pool')(X)

  #End Code Here

  #Output Layer:
  X=Flatten()(X)
  X=Dense(classes,activation='softmax',name='fc'+str(classes),kernel_initializer=glorot_uniform(seed=0))(X)

  #Create Model:
  model=Model(inputs=X_input,outputs=X,name='ResNet50')

  return model

model =ResNet50(input_shape=(im_size,im_size,channels),classes=classes)
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
images,Y=shuffle(images,Y,random_state=1)
X_train,X_test,y_train,y_test=train_test_split(images,Y,test_size=0.2,random_state=1)
print(X_train.shape,'\n',X_test.shape,'\n',y_train.shape,'\n',y_test.shape)

# Convert sparse matrices to dense arrays and then to integer labels
y_train_labels = y_train.toarray().argmax(axis=1)  # Convert to dense array and get class indices
y_test_labels = y_test.toarray().argmax(axis=1)    # Convert to dense array and get class indices

# Convert integer labels to one-hot encoded format using Keras's to_categorical
from tensorflow.keras.utils import to_categorical
y_train = to_categorical(y_train_labels, num_classes=3) # Use integer labels
y_test = to_categorical(y_test_labels, num_classes=3)   # Use integer labels

model.fit(X_train,y_train,epochs=10,batch_size=32)

preds=model.evaluate(X_test,y_test)
print("Loss= "+str(preds[0]))
print("Test Accuracy= "+str(preds[1]))

"""#**Testing Model on Unseen Data**"""

from matplotlib.pyplot import imread,imshow
from keras.preprocessing import image
import numpy as np
img_path="test_image.jpg"
img=image.load_img(img_path,target_size=(224,224))
X=image.img_to_array(img)
X=np.expand_dims(X,axis=0)
X=preprocess_input(X)
images=np.array(X)
images=images/255.0
print("Input Image Shape:\n",images.shape)
my_image=imread(img_path)
imshow(my_image)
prediction=model.predict(images)
print("Prediction= "+str(np.argmax(prediction)))



