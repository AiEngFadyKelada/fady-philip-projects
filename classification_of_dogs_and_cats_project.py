# -*- coding: utf-8 -*-
"""Classification of dogs and cats project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zFcnAOdRJaVmzYiZmR-eTQRnaAOvGO90
"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow import keras
from sklearn. model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import pickle
import random

# %matplotlib inline

categories=os.listdir('dataset')
categories.remove('.ipynb_checkpoints')
print(categories)

animals=[]
for item in categories:
  all_categ=os.listdir('dataset'+'/'+item)
  print(all_categ[:])
  filenames=[j for j in os.listdir('dataset'+'/'+item) if j.endswith('.jpg')]
  for f in filenames:
    animals.append((item,str('dataset' +'/'+item)))
print(animals)
print(len(animals))

images=[]
training_data=[]
im_size=100
for category in categories:
  class_num=categories.index(category)
  for img in os.listdir('dataset'+'/'+category):
    img=cv2.imread('dataset'+'/'+category+'/'+img,cv2.IMREAD_GRAYSCALE)
    img=cv2.resize(img,(im_size,im_size))
    images.append(img)
    training_data.append([img,class_num])

print(training_data)

random.shuffle(training_data)
for sample in training_data[:10]:
  print(sample[class_num])

x=[]
y=[]
for feature,label in training_data:
  x.append(feature)
  y.append(label)

x=np.array(x)
x=x.reshape(-1,im_size,im_size)
y=np.array(y)

x

y

X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

model=keras.models.Sequential([
    keras.layers.Flatten(input_shape=(im_size,im_size)),
    keras.layers.Dense(512,activation=tf.nn.relu),
    keras.layers.Dense(512,activation=tf.nn.relu),
    keras.layers.Dense(256,activation=tf.nn.relu),
    keras.layers.Dense(256,activation=tf.nn.relu),
    keras.layers.Dense(128,activation=tf.nn.relu),
    keras.layers.Dense(128,activation=tf.nn.relu),
    keras.layers.Dense(64,activation=tf.nn.relu),
    keras.layers.Dense(64,activation=tf.nn.relu),
    keras.layers.Dense(32,activation=tf.nn.relu),
    keras.layers.Dense(2,activation=tf.nn.softmax)
])
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model.fit(x,y,epochs=100)

test_loss,test_acc=model.evaluate(X_test,y_test)
test_acc

output=model.predict(X_test)
y_pred=np.argmax(output,axis=1)
print(y_pred)

print(accuracy_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

































































































